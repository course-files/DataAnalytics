<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Allan Omondi" />

<meta name="date" content="2025-05-03" />

<title>Multiple Linear Regression</title>

<script src="2_multiple_linear_regression_files/header-attrs-2.29/header-attrs.js"></script>
<script src="2_multiple_linear_regression_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="2_multiple_linear_regression_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="2_multiple_linear_regression_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="2_multiple_linear_regression_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="2_multiple_linear_regression_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="2_multiple_linear_regression_files/navigation-1.1/tabsets.js"></script>
<link href="2_multiple_linear_regression_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="2_multiple_linear_regression_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div id="header">



<h1 class="title toc-ignore">Multiple Linear Regression</h1>
<h4 class="author">Allan Omondi</h4>
<h4 class="date">2025-05-03</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#load-the-dataset" id="toc-load-the-dataset"><span
class="toc-section-number">1</span> Load the Dataset</a></li>
<li><a href="#initial-eda" id="toc-initial-eda"><span
class="toc-section-number">2</span> Initial EDA</a>
<ul>
<li><a href="#measures-of-frequency"
id="toc-measures-of-frequency"><span
class="toc-section-number">2.1</span> <u><strong>Measures of
Frequency</strong></u></a></li>
<li><a href="#measures-of-central-tendency"
id="toc-measures-of-central-tendency"><span
class="toc-section-number">2.2</span> <u><strong>Measures of Central
Tendency</strong></u></a></li>
<li><a href="#measures-of-distribution"
id="toc-measures-of-distribution"><span
class="toc-section-number">2.3</span> <u><strong>Measures of
Distribution</strong></u></a>
<ul>
<li><a href="#variance" id="toc-variance"><span
class="toc-section-number">2.3.1</span>
<strong>Variance</strong></a></li>
<li><a href="#standard-deviation" id="toc-standard-deviation"><span
class="toc-section-number">2.3.2</span> <strong>Standard
Deviation</strong></a></li>
<li><a href="#kurtosis" id="toc-kurtosis"><span
class="toc-section-number">2.3.3</span>
<strong>Kurtosis</strong></a></li>
<li><a href="#skewness" id="toc-skewness"><span
class="toc-section-number">2.3.4</span>
<strong>Skewness</strong></a></li>
</ul></li>
<li><a href="#measures-of-relationship"
id="toc-measures-of-relationship"><span
class="toc-section-number">2.4</span> <u><strong>Measures of
Relationship</strong></u></a>
<ul>
<li><a href="#covariance" id="toc-covariance"><span
class="toc-section-number">2.4.1</span>
<strong>Covariance</strong></a></li>
<li><a href="#correlation" id="toc-correlation"><span
class="toc-section-number">2.4.2</span>
<strong>Correlation</strong></a></li>
</ul></li>
<li><a href="#basic-visualizations" id="toc-basic-visualizations"><span
class="toc-section-number">2.5</span> <u><strong>Basic
Visualizations</strong></u></a>
<ul>
<li><a href="#histogram" id="toc-histogram"><span
class="toc-section-number">2.5.1</span>
<strong>Histogram</strong></a></li>
<li><a href="#box-and-whisker-plot" id="toc-box-and-whisker-plot"><span
class="toc-section-number">2.5.2</span> <strong>Box and Whisker
Plot</strong></a></li>
<li><a href="#missing-data-plot" id="toc-missing-data-plot"><span
class="toc-section-number">2.5.3</span> <strong>Missing Data
Plot</strong></a></li>
<li><a href="#correlation-plot" id="toc-correlation-plot"><span
class="toc-section-number">2.5.4</span> <strong>Correlation
Plot</strong></a></li>
<li><a href="#scatter-plot" id="toc-scatter-plot"><span
class="toc-section-number">2.5.5</span> <strong>Scatter
Plot</strong></a></li>
</ul></li>
</ul></li>
<li><a href="#statistical-test" id="toc-statistical-test"><span
class="toc-section-number">3</span> Statistical Test</a></li>
<li><a href="#diagnostic-eda" id="toc-diagnostic-eda"><span
class="toc-section-number">4</span> Diagnostic EDA</a>
<ul>
<li><a href="#test-of-linearity" id="toc-test-of-linearity"><span
class="toc-section-number">4.1</span> <u><strong>Test of
Linearity</strong></u></a></li>
<li><a href="#test-of-independence-of-errors"
id="toc-test-of-independence-of-errors"><span
class="toc-section-number">4.2</span> <u><strong>Test of Independence of
Errors</strong></u></a></li>
<li><a href="#test-of-normality" id="toc-test-of-normality"><span
class="toc-section-number">4.3</span> <u><strong>Test of
Normality</strong></u></a></li>
<li><a href="#test-of-homoscedasticity"
id="toc-test-of-homoscedasticity"><span
class="toc-section-number">4.4</span> <u><strong>Test of
Homoscedasticity</strong></u></a></li>
<li><a href="#quantitative-validation-of-assumptions"
id="toc-quantitative-validation-of-assumptions"><span
class="toc-section-number">4.5</span> <u><strong>Quantitative Validation
of Assumptions</strong></u></a></li>
<li><a href="#test-of-multicollinearity"
id="toc-test-of-multicollinearity"><span
class="toc-section-number">4.6</span> Test of Multicollinearity</a></li>
</ul></li>
<li><a href="#interpretation-of-the-results"
id="toc-interpretation-of-the-results"><span
class="toc-section-number">5</span> Interpretation of the Results</a>
<ul>
<li><a href="#academic-statement" id="toc-academic-statement"><span
class="toc-section-number">5.1</span> Academic Statement</a></li>
<li><a href="#business-analysis" id="toc-business-analysis"><span
class="toc-section-number">5.2</span> Business Analysis</a></li>
<li><a href="#limitations" id="toc-limitations"><span
class="toc-section-number">5.3</span> Limitations</a></li>
</ul></li>
</ul>
</div>

<div id="load-the-dataset" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Load the Dataset</h1>
<pre class="r"><code>pacman::p_load(&quot;readr&quot;)

advertising_data &lt;- read_csv(&quot;./data/advertising.csv&quot;)
head(advertising_data)</code></pre>
<pre><code>## # A tibble: 6 × 4
##   YouTube TikTok Facebook Sales
##     &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;
## 1    1200    800     1000  95.3
## 2    1500    900     1100 101. 
## 3    1300    850     1050  99.5
## 4    1600    950     1150 107. 
## 5    1100    780      980  93.0
## 6    1700   1000     1200 108.</code></pre>
</div>
<div id="initial-eda" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Initial EDA</h1>
<p><u><strong>View the Dimensions</strong></u></p>
<p>The number of observations and the number of variables.</p>
<pre class="r"><code>dim(advertising_data)</code></pre>
<pre><code>## [1] 10  4</code></pre>
<p><u><strong>View the Data Types</strong></u></p>
<pre class="r"><code>sapply(advertising_data, class)</code></pre>
<pre><code>##   YouTube    TikTok  Facebook     Sales 
## &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot;</code></pre>
<pre class="r"><code>str(advertising_data)</code></pre>
<pre><code>## spc_tbl_ [10 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ YouTube : num [1:10] 1200 1500 1300 1600 1100 1700 1400 1800 1250 1550
##  $ TikTok  : num [1:10] 800 900 850 950 780 1000 880 1020 820 970
##  $ Facebook: num [1:10] 1000 1100 1050 1150 980 1200 1080 1220 1010 1130
##  $ Sales   : num [1:10] 95.3 101.2 99.5 106.8 93 ...
##  - attr(*, &quot;spec&quot;)=
##   .. cols(
##   ..   YouTube = col_double(),
##   ..   TikTok = col_double(),
##   ..   Facebook = col_double(),
##   ..   Sales = col_double()
##   .. )
##  - attr(*, &quot;problems&quot;)=&lt;externalptr&gt;</code></pre>
<p><u><strong>Descriptive Statistics</strong></u></p>
<div id="measures-of-frequency" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> <u><strong>Measures
of Frequency</strong></u></h2>
<p>This is applicable in cases where you have categorical variables,
e.g., 60% of the observations are male and 40% are female (2
categories).</p>
</div>
<div id="measures-of-central-tendency" class="section level2"
number="2.2">
<h2><span class="header-section-number">2.2</span> <u><strong>Measures
of Central Tendency</strong></u></h2>
<p>The median and the mean of each numeric variable:</p>
<pre class="r"><code>summary(advertising_data)</code></pre>
<pre><code>##     YouTube         TikTok          Facebook        Sales       
##  Min.   :1100   Min.   : 780.0   Min.   : 980   Min.   : 93.02  
##  1st Qu.:1262   1st Qu.: 827.5   1st Qu.:1020   1st Qu.: 97.27  
##  Median :1450   Median : 890.0   Median :1090   Median :101.95  
##  Mean   :1440   Mean   : 897.0   Mean   :1092   Mean   :101.93  
##  3rd Qu.:1588   3rd Qu.: 965.0   3rd Qu.:1145   3rd Qu.:106.17  
##  Max.   :1800   Max.   :1020.0   Max.   :1220   Max.   :111.82</code></pre>
</div>
<div id="measures-of-distribution" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> <u><strong>Measures
of Distribution</strong></u></h2>
<p>Measuring the variability in the dataset is important because the
amount of variability determines <strong>how well you can
generalize</strong> results from the sample to a new observation in the
population.</p>
<p>Low variability is ideal because it means that you can better predict
information about the population based on the sample data. High
variability means that the values are less consistent, thus making it
harder to make predictions.</p>
<div id="variance" class="section level3" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span>
<strong>Variance</strong></h3>
<pre class="r"><code>sapply(advertising_data[,], var)</code></pre>
<pre><code>##     YouTube      TikTok    Facebook       Sales 
## 52111.11111  7267.77778  6951.11111    36.13165</code></pre>
</div>
<div id="standard-deviation" class="section level3" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> <strong>Standard
Deviation</strong></h3>
<pre class="r"><code>sapply(advertising_data[,], sd)</code></pre>
<pre><code>##   YouTube    TikTok  Facebook     Sales 
## 228.27858  85.25126  83.37332   6.01096</code></pre>
</div>
<div id="kurtosis" class="section level3" number="2.3.3">
<h3><span class="header-section-number">2.3.3</span>
<strong>Kurtosis</strong></h3>
<p>The Kurtosis informs us of how often outliers occur in the results.
There are different formulas for calculating kurtosis. Specifying “type
= 2” allows us to use the 2nd formula which is the same kurtosis formula
used in other statistical software like SPSS and SAS.</p>
<p>In “type = 2” (used in SPSS and SAS):</p>
<ol style="list-style-type: decimal">
<li><p>Kurtosis &lt; 3 implies a low number of outliers</p></li>
<li><p>Kurtosis = 3 implies a medium number of outliers</p></li>
<li><p>Kurtosis &gt; 3 implies a high number of outliers</p></li>
</ol>
<pre class="r"><code>pacman::p_load(&quot;e1071&quot;)
sapply(advertising_data[,],  kurtosis, type = 2)</code></pre>
<pre><code>##    YouTube     TikTok   Facebook      Sales 
## -1.0800892 -1.4726766 -1.1989242 -0.8697324</code></pre>
</div>
<div id="skewness" class="section level3" number="2.3.4">
<h3><span class="header-section-number">2.3.4</span>
<strong>Skewness</strong></h3>
<p>The skewness is used to identify the asymmetry of the distribution of
results. Similar to kurtosis, there are several ways of computing the
skewness.</p>
<p>Using “type = 2” (common in other statistical software like SPSS and
SAS) can be interpreted as:</p>
<ol style="list-style-type: decimal">
<li><p>Skewness between -0.4 and 0.4 (inclusive) implies that there is
no skew in the distribution of results; the distribution of results is
symmetrical; it is a normal distribution; a Gaussian
distribution.</p></li>
<li><p>Skewness above 0.4 implies a positive skew; a right-skewed
distribution.</p></li>
<li><p>Skewness below -0.4 implies a negative skew; a left-skewed
distribution.</p></li>
</ol>
<pre class="r"><code>sapply(advertising_data[,], skewness, type = 2)</code></pre>
<pre><code>##    YouTube     TikTok   Facebook      Sales 
## 0.08266188 0.09234643 0.19089944 0.10505432</code></pre>
</div>
</div>
<div id="measures-of-relationship" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> <u><strong>Measures
of Relationship</strong></u></h2>
<div id="covariance" class="section level3" number="2.4.1">
<h3><span class="header-section-number">2.4.1</span>
<strong>Covariance</strong></h3>
<p>Covariance is a statistical measure that indicates the direction of
the linear relationship between two variables. It assesses whether
increases in one variable correspond to increases or decreases in
another.​</p>
<ul>
<li><p><strong>Positive Covariance:</strong> When one variable
increases, the other tends to increase as well.</p></li>
<li><p><strong>Negative Covariance:</strong> When one variable
increases, the other tends to decrease.</p></li>
<li><p><strong>Zero Covariance:</strong> No linear relationship exists
between the variables.</p></li>
</ul>
<p>While covariance indicates the direction of a relationship, it does
not convey the strength or consistency of the relationship. The
correlation coefficient is used to indicate the strength of the
relationship.</p>
<pre class="r"><code>cov(advertising_data, method = &quot;spearman&quot;)</code></pre>
<pre><code>##           YouTube   TikTok Facebook    Sales
## YouTube  9.166667 9.055556 9.166667 9.055556
## TikTok   9.055556 9.166667 9.055556 8.944444
## Facebook 9.166667 9.055556 9.166667 9.055556
## Sales    9.055556 8.944444 9.055556 9.166667</code></pre>
</div>
<div id="correlation" class="section level3" number="2.4.2">
<h3><span class="header-section-number">2.4.2</span>
<strong>Correlation</strong></h3>
<p>A strong correlation between variables enables us to better predict
the value of the dependent variable using the value of the independent
variable. However, a weak correlation between two variables does not
help us to predict the value of the dependent variable from the value of
the independent variable. This is useful only if there is a linear
association between the variables.</p>
<p>We can measure the statistical significance of the correlation using
Spearman’s rank correlation <em>rho</em>. This shows us if the variables
are significantly monotonically related. A monotonic relationship
between two variables implies that as one variable increases, the other
variable either consistently increases or consistently decreases. The
key characteristic is the preservation of the direction of change,
though the rate of change may vary.</p>
<p><strong>Option 1:</strong> Conduct a correlation test between the
dependent variable and each independent variable one at a time.</p>
<pre class="r"><code>cor.test(advertising_data$Sales, advertising_data$YouTube, method = &quot;spearman&quot;)</code></pre>
<pre><code>## 
##  Spearman&#39;s rank correlation rho
## 
## data:  advertising_data$Sales and advertising_data$YouTube
## S = 2, p-value &lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.9878788</code></pre>
<pre class="r"><code>cor.test(advertising_data$Sales, advertising_data$TikTok, method = &quot;spearman&quot;)</code></pre>
<pre><code>## 
##  Spearman&#39;s rank correlation rho
## 
## data:  advertising_data$Sales and advertising_data$TikTok
## S = 4, p-value &lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.9757576</code></pre>
<pre class="r"><code>cor.test(advertising_data$Sales, advertising_data$Facebook, method = &quot;spearman&quot;)</code></pre>
<pre><code>## 
##  Spearman&#39;s rank correlation rho
## 
## data:  advertising_data$Sales and advertising_data$Facebook
## S = 2, p-value &lt; 2.2e-16
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.9878788</code></pre>
<p><strong>Option 2:</strong> To view the correlation of all variables
at the same time</p>
<pre class="r"><code>cor(advertising_data, method = &quot;spearman&quot;)</code></pre>
<pre><code>##            YouTube    TikTok  Facebook     Sales
## YouTube  1.0000000 0.9878788 1.0000000 0.9878788
## TikTok   0.9878788 1.0000000 0.9878788 0.9757576
## Facebook 1.0000000 0.9878788 1.0000000 0.9878788
## Sales    0.9878788 0.9757576 0.9878788 1.0000000</code></pre>
</div>
</div>
<div id="basic-visualizations" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> <u><strong>Basic
Visualizations</strong></u></h2>
<div id="histogram" class="section level3" number="2.5.1">
<h3><span class="header-section-number">2.5.1</span>
<strong>Histogram</strong></h3>
<pre class="r"><code>par(mfrow = c(1, 2))
for (i in 1:4) {
  if (is.numeric(advertising_data[[i]])) {
    hist(advertising_data[[i]],
         main = names(advertising_data)[i],
         xlab = names(advertising_data)[i])
  } else {
    message(paste(&quot;Column&quot;, names(advertising_data)[i], &quot;is not numeric and will be skipped.&quot;))
  }
}</code></pre>
<p><img
src="2_multiple_linear_regression_files/figure-html/visualization_histogram-1.png" /><!-- --><img
src="2_multiple_linear_regression_files/figure-html/visualization_histogram-2.png" /><!-- --></p>
</div>
<div id="box-and-whisker-plot" class="section level3" number="2.5.2">
<h3><span class="header-section-number">2.5.2</span> <strong>Box and
Whisker Plot</strong></h3>
<pre class="r"><code># `boxplot()` This is the function used to plot the box and whisker plot visualization
par(mfrow = c(1, 2))
for (i in 1:4) {
  if (is.numeric(advertising_data[[i]])) {
    boxplot(advertising_data[[i]], main = names(advertising_data)[i])
  } else {
    message(paste(&quot;Column&quot;, names(advertising_data)[i], &quot;is not numeric and will be skipped.&quot;))
  }
}</code></pre>
<p><img
src="2_multiple_linear_regression_files/figure-html/visualization_boxplot-1.png" /><!-- --><img
src="2_multiple_linear_regression_files/figure-html/visualization_boxplot-2.png" /><!-- --></p>
</div>
<div id="missing-data-plot" class="section level3" number="2.5.3">
<h3><span class="header-section-number">2.5.3</span> <strong>Missing
Data Plot</strong></h3>
<pre class="r"><code>pacman::p_load(&quot;Amelia&quot;)

missmap(advertising_data, col = c(&quot;red&quot;, &quot;grey&quot;), legend = TRUE)</code></pre>
<p><img
src="2_multiple_linear_regression_files/figure-html/missing_data_plot-1.png" /><!-- --></p>
</div>
<div id="correlation-plot" class="section level3" number="2.5.4">
<h3><span class="header-section-number">2.5.4</span> <strong>Correlation
Plot</strong></h3>
<pre class="r"><code>pacman::p_load(&quot;ggcorrplot&quot;)

ggcorrplot(cor(advertising_data[,]))</code></pre>
<p><img
src="2_multiple_linear_regression_files/figure-html/correlation_plot-1.png" /><!-- --></p>
</div>
<div id="scatter-plot" class="section level3" number="2.5.5">
<h3><span class="header-section-number">2.5.5</span> <strong>Scatter
Plot</strong></h3>
<pre class="r"><code>pacman::p_load(&quot;corrplot&quot;)

pairs(advertising_data$Sales ~ ., data = advertising_data, col = advertising_data$Sales)</code></pre>
<p><img
src="2_multiple_linear_regression_files/figure-html/scatter_plot_1-1.png" /><!-- --></p>
<pre class="r"><code>pacman::p_load(&quot;ggplot2&quot;)
ggplot(advertising_data,
       aes(x = YouTube, y = Sales)) + 
  geom_point() +
  geom_smooth(method = lm) +
  labs(
    title = &quot;Relationship between Sales Revenue and \nExpenditure on YouTube Marketing&quot;,
    x = &quot;Expenditure&quot;,
    y = &quot;Sales&quot;
  )</code></pre>
<p><img
src="2_multiple_linear_regression_files/figure-html/scatter_plot_2-1.png" /><!-- --></p>
<pre class="r"><code>pacman::p_load(&quot;dplyr&quot;)
advertising_data_composite &lt;- advertising_data %&gt;%
  mutate(Total_Expenditure = YouTube + TikTok + Facebook)

ggplot(advertising_data_composite,
       aes(x = Total_Expenditure, y = Sales)) +
  geom_point() +
  geom_smooth(method = lm) +
  labs(
    title = &quot;Relationship between Sales Revenue and \nTotal Marketing Expenditure&quot;,
    x = &quot;Total Expenditure&quot;,
    y = &quot;Sales&quot;
  )</code></pre>
<p><img
src="2_multiple_linear_regression_files/figure-html/scatter_plot_3-1.png" /><!-- --></p>
</div>
</div>
</div>
<div id="statistical-test" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Statistical Test</h1>
<p>We then apply a simultaneous multiple linear regression as a
statistical test for regression. The term “simultaneous” refers to how
the predictor variables are entered and considered in the statistical
test. It means that all the predictor variables included in the model
are entered and evaluated at the same time.</p>
<p>View the summary of the model.</p>
<pre class="r"><code>summary(mlr_test)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Sales ~ YouTube + TikTok + Facebook, data = advertising_data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.5436 -0.6159  0.1056  0.6598  1.5978 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 32.019096  24.432018   1.311    0.238
## YouTube      0.006088   0.015876   0.384    0.715
## TikTok      -0.007662   0.032263  -0.237    0.820
## Facebook     0.062289   0.048787   1.277    0.249
## 
## Residual standard error: 1.2 on 6 degrees of freedom
## Multiple R-squared:  0.9734, Adjusted R-squared:  0.9602 
## F-statistic: 73.32 on 3 and 6 DF,  p-value: 4.055e-05</code></pre>
<p>To obtain a 95% confidence interval:</p>
<pre class="r"><code>confint(mlr_test, level = 0.95)</code></pre>
<pre><code>##                    2.5 %      97.5 %
## (Intercept) -27.76389745 91.80208927
## YouTube      -0.03275855  0.04493539
## TikTok       -0.08660653  0.07128263
## Facebook     -0.05708823  0.18166580</code></pre>
</div>
<div id="diagnostic-eda" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Diagnostic EDA</h1>
<p>Diagnostic EDA is performed to validate that the regression
assumptions are true with respect to the statistical test. Validating
the regression assumption in turn ensures that the statistical tests
applied are appropriate for the data and helps to prevent incorrect
conclusions.</p>
<div id="test-of-linearity" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> <u><strong>Test of
Linearity</strong></u></h2>
<p>The test of linearity is used to assess whether the relationship
between the dependent variables and the independent variables is linear.
This is necessary given that linearity is one of the key assumptions of
statistical tests of regression and verifying it is crucial for ensuring
the validity of the model’s estimates and predictions.</p>
<p>A plot of the residuals versus the fitted values enables us to test
for linearity. For the model to pass the test of linearity, there should
be no pattern in the distribution of residuals and the residuals should
be randomly placed around the 0.0 residual line, i.e., the residuals
should randomly vary around the mean of the value of the response
variable.</p>
<pre class="r"><code>plot(mlr_test, which = 1)</code></pre>
<p><img
src="2_multiple_linear_regression_files/figure-html/test_of_linearity-1.png" /><!-- --></p>
</div>
<div id="test-of-independence-of-errors" class="section level2"
number="4.2">
<h2><span class="header-section-number">4.2</span> <u><strong>Test of
Independence of Errors</strong></u></h2>
<p>This test is necessary to confirm that each observation is
independent of the other. It helps to identify
<strong>autocorrelation</strong> that is introduced when the data is
collected over a close period of time or when one observation is related
to another observation. Autocorrelation leads to underestimated standard
errors and inflated t-statistics. It can also make findings appear more
significant than they actually are.</p>
<p>The “<strong>Durbin-Watson Test</strong>” can be used as a test of
independence of errors (test of autocorrelation).</p>
<ul>
<li><p>The null hypothesis, H<sub>0</sub>, is that there is no
autocorrelation</p></li>
<li><p>The alternative hypothesis, H<sub>a</sub>, is that there is
autocorrelation</p></li>
</ul>
<p>If the p-value is greater than 0.05 then there is no evidence to
reject the null hypothesis that “there is no autocorrelation”. The
results below show a p-value of 0.5316, therefore, the test of
independence of errors around the regression line passes.</p>
<pre class="r"><code>pacman::p_load(&quot;lmtest&quot;)
dwtest(mlr_test)</code></pre>
<pre><code>## 
##  Durbin-Watson test
## 
## data:  mlr_test
## DW = 2.1498, p-value = 0.5316
## alternative hypothesis: true autocorrelation is greater than 0</code></pre>
</div>
<div id="test-of-normality" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> <u><strong>Test of
Normality</strong></u></h2>
<p>The test of normality assesses whether the residuals are normally
distributed, i.e., most residuals (errors) are close to zero and large
errors are rare. A Q-Q plot can be used to conduct the test of
normality.</p>
<p>A Q-Q plot is a scatterplot of the quantiles of the residuals against
the quantiles of a normal distribution. Quantiles are statistical values
that divide a dataset or probability distribution into equal-sized
intervals. They help in understanding how data is distributed by marking
specific points that separate the data into groups of equal size.
Examples of quantiles include: quartiles (4 equal parts), percentiles
(100 equal parts), deciles (10 equal parts), etc.</p>
<p>If the points in the Q-Q plot fall along a straight line, then the
normality assumption is satisfied. If the points in the Q-Q plot do not
fall along a straight line, then the normality assumption is not
satisfied.</p>
<pre class="r"><code>plot(mlr_test, which = 2)</code></pre>
<p><img
src="2_multiple_linear_regression_files/figure-html/test_of_normality-1.png" /><!-- --></p>
</div>
<div id="test-of-homoscedasticity" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> <u><strong>Test of
Homoscedasticity</strong></u></h2>
<p>Homoscedasticity requires that the spread of residuals should be
constant across all levels of the independent variable. A scale-location
plot (a.k.a. spread-location plot) can be used to conduct a test of
homoscedasticity.</p>
<p>The x-axis shows the fitted (predicted) values from the model and the
y-axis shows the square root of the standardized residuals. The red line
is added to help visualize any patterns.</p>
<p>In a model with homoscedastic errors (equal variance across all
predicted values):</p>
<ul>
<li><p>Points should be randomly scattered around a horizontal
line</p></li>
<li><p>The smooth line should be approximately horizontal</p></li>
<li><p>The vertical spread of points should be roughly equal across all
fitted values</p></li>
<li><p>No obvious patterns, funnels, or trends should be
visible</p></li>
</ul>
<p>Points forming a cone shape that widens from left to right suggests
heteroscedasticity with increasing variance for larger fitted
values.</p>
<pre class="r"><code>plot(mlr_test, which = 3)</code></pre>
<p><img
src="2_multiple_linear_regression_files/figure-html/test_of_homoscedasticity-1.png" /><!-- --></p>
</div>
<div id="quantitative-validation-of-assumptions" class="section level2"
number="4.5">
<h2><span class="header-section-number">4.5</span>
<u><strong>Quantitative Validation of Assumptions</strong></u></h2>
<p>The graphical representations of the various tests of assumptions
should be accompanied by quantitative values. The <code>gvlma</code>
package (Global Validation of Linear Models Assumptions) is useful for
this purpose.</p>
<pre class="r"><code>pacman::p_load(&quot;gvlma&quot;)
gvlma_results &lt;- gvlma(mlr_test)
summary(gvlma_results)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Sales ~ YouTube + TikTok + Facebook, data = advertising_data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.5436 -0.6159  0.1056  0.6598  1.5978 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 32.019096  24.432018   1.311    0.238
## YouTube      0.006088   0.015876   0.384    0.715
## TikTok      -0.007662   0.032263  -0.237    0.820
## Facebook     0.062289   0.048787   1.277    0.249
## 
## Residual standard error: 1.2 on 6 degrees of freedom
## Multiple R-squared:  0.9734, Adjusted R-squared:  0.9602 
## F-statistic: 73.32 on 3 and 6 DF,  p-value: 4.055e-05
## 
## 
## ASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS
## USING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:
## Level of Significance =  0.05 
## 
## Call:
##  gvlma(x = mlr_test) 
## 
##                      Value p-value                Decision
## Global Stat        0.92304  0.9212 Assumptions acceptable.
## Skewness           0.04975  0.8235 Assumptions acceptable.
## Kurtosis           0.30420  0.5813 Assumptions acceptable.
## Link Function      0.41234  0.5208 Assumptions acceptable.
## Heteroscedasticity 0.15675  0.6922 Assumptions acceptable.</code></pre>
</div>
<div id="test-of-multicollinearity" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> Test of
Multicollinearity</h2>
<p>Multicollinearity arises when two or more independent variables
(predictors) are highly intercorrelated. The <strong>Variance Inflation
Factor (VIF)</strong> quantifies how much the variance of a coefficient
estimate is “inflated” due to multicollinearity. A VIF of 1 indicates no
collinearity; values above 5 suggest problematic levels of collinearity.
High VIF values (VIF &gt; 5) suggest that the coefficient estimates are
less reliable due to the correlations between predictors.</p>
<pre class="r"><code>pacman::p_load(&quot;car&quot;)
vif(mlr_test)</code></pre>
<pre><code>##   YouTube    TikTok  Facebook 
##  82.13782  47.30912 103.46518</code></pre>
</div>
</div>
<div id="interpretation-of-the-results" class="section level1"
number="5">
<h1><span class="header-section-number">5</span> Interpretation of the
Results</h1>
<div id="academic-statement" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Academic
Statement</h2>
<p>A simultaneous multiple linear regression analysis was conducted on
data from 10 observations (N=10) to examine whether advertising
expenditures on YouTube, TikTok, and Facebook collectively predict
Sales. The results indicated that neither expenses on YouTube (<span
class="math inline">\(\beta\)</span> = 0.01, 95% CI [-.03, .04], SE =
0.02, <em>t</em>(6) = 0.38, <em>p</em> = .715), nor TikTok (<span
class="math inline">\(\beta\)</span> = -0.01, 95% CI [-.09, .07], SE =
0.03, <em>t</em>(6) = -0.24, <em>p</em> = .820) nor Facebook (<span
class="math inline">\(\beta\)</span> = 0.06, 95% CI [-.06, .18], SE =
0.05, <em>t</em>(6) = 1.28, <em>p</em> = .249) individually
significantly predicted Sales (all <em>p</em> &gt; 0.05). The model
explained 97.34% of the variance in Sales (Multiple R<sup>2</sup> = .97,
Adjusted R<sup>2</sup> = .96, <em>F</em>(3, 6) = 73.32, <em>p</em> &lt;
.001). The intercept was 32.02, 95% CI [-27.76, 91.80], SE = 24.43,
<em>t</em>(6) = 1.31, <em>p</em> = .238. The residual standard error was
1.2, indicating a robust model. The full results are presented in the
table below.</p>
<table>
<caption>Regression Coefficients Predicting Sales from Multiple
Advertising Channels</caption>
<thead>
<tr class="header">
<th align="center">Predictor</th>
<th align="center"><span class="math inline">\(\beta\)</span></th>
<th align="center">95% CI</th>
<th align="center">SE</th>
<th align="center"><em>t</em>(6)</th>
<th align="center"><em>p</em></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">(Intercept)</td>
<td align="center">32.02</td>
<td align="center">[-27.76, 91.80]</td>
<td align="center">24.43</td>
<td align="center">1.31</td>
<td align="center">.238</td>
</tr>
<tr class="even">
<td align="center">YouTube</td>
<td align="center">0.01</td>
<td align="center">[-.03, .04]</td>
<td align="center">0.02</td>
<td align="center">0.38</td>
<td align="center">.715</td>
</tr>
<tr class="odd">
<td align="center">TikTok</td>
<td align="center">-0.01</td>
<td align="center">[-.09, .07]</td>
<td align="center">0.03</td>
<td align="center">-0.24</td>
<td align="center">.820</td>
</tr>
<tr class="even">
<td align="center">Facebook</td>
<td align="center">0.06</td>
<td align="center">[-.06, .18]</td>
<td align="center">0.05</td>
<td align="center">1.28</td>
<td align="center">.249</td>
</tr>
</tbody>
</table>
<p><strong><em>Note.</em></strong> N = 10; SE = standard error;
CI = confidence interval.</p>
<p>Even though the results indicated a robust model whereby
advertisement expenditures collectively predict sales, individual
parameter estimates did not reach statistical significance when
controlling for the other parameters. This suggests that the advertising
channels collectively explain variation in Sales but do not uniquely
predict Sales in this small sample. This may reflect multicollinearity
among the different advertising platforms or limited statistical power
due to the small sample size (<em>N</em> = 10). Future research should
investigate these predictors with a larger sample and assess potential
collinearity.</p>
</div>
<div id="business-analysis" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Business
Analysis</h2>
<p>Although aggregate digital advertising spend across YouTube, TikTok,
and Facebook is highly predictive of Sales (accounting for nearly all
observed variation), the absence of statistically significant individual
coefficients indicates that no single channel can be reliably credited
with driving incremental Sales in this dataset. This finding suggests
that, within the current investment levels and the constraints of a
small sample, the three platforms function as a cohesive portfolio
rather than as independent drivers of sales revenue. Recommendation for
management:</p>
<ol style="list-style-type: decimal">
<li>Continue to view YouTube, TikTok, and Facebook as complementary
elements of a unified digital marketing strategy focusing on the total
expenditure rather than favouring a single platform.</li>
</ol>
</div>
<div id="limitations" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Limitations</h2>
<ol style="list-style-type: decimal">
<li><p>Small Sample Size (N = 10): Using a limited number of
observations restricts statistical power and inflates standard errors,
raising the risk of a Type II error (failing to detect true channel
effects).</p></li>
<li><p>Potential Multicollinearity: High intercorrelations among
YouTube, TikTok, and Facebook expenditures may obscure unique
contributions.</p></li>
<li><p>Restricted Expenditure Range: Limited range of advertisement
expenditures impairs the ability to detect linear effects.</p></li>
<li><p>Methodology: Lack of experimental variation in advertisement
expenditure limits causal attribution to any single platform.</p></li>
</ol>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
